{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning\n",
    "=====\n",
    "\n",
    "##### Important concepts\n",
    "* ENG - Electrical Number Group - a grouping used to divide product into rough categories.\n",
    "* ETIM class - a grouping used to divide products into detailed categories.\n",
    "* Technical description - a text field describing each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import scipy.sparse as sp\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Change working directory to get the file\n",
    "os.chdir('/Users/pkg/Springboard')\n",
    "\n",
    "# Open pickled file from the data wrangling section and set working directory\n",
    "with open('data_wrangling.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)\n",
    "    \n",
    "os.chdir('/Users/pkg/Springboard/Intermediate Data Science with Python/Python_Capstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels'  shape: (202216,)\n",
      "ex_var's shape: (202216, 2)\n",
      "\n",
      "labels is of type <class 'pandas.core.series.Series'>\n",
      "ex_var is of type <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "first label: EC003251\n",
      "first ENG: 10\n",
      "first technical description: VDF/EMC frekvensomformerkabel med symmetrisk jordleder. Dobbel skjerming bestående av folie og flettet fortinnet kobberskjerm. Laget for å gi lavest mulig koblingsimpedans. Kan benyttes utendørs. For spenning 0,6/1Kv med en testspenning på 4000V\n"
     ]
    }
   ],
   "source": [
    "# Separating the labels from the rest of the data set\n",
    "labels = df['ETIM_class']\n",
    "ex_var = df[['EN_group', 'Technical_description']]\n",
    "\n",
    "print(\"labels'  shape:\", labels.shape)\n",
    "print(\"ex_var's shape:\", ex_var.shape)\n",
    "print(\"\")\n",
    "print(\"labels is of type\", type(labels))\n",
    "print(\"ex_var is of type\", type(ex_var))\n",
    "print(\"\")\n",
    "print(\"first label:\", labels.iloc[0])\n",
    "print(\"first ENG:\", ex_var.iloc[0,0])\n",
    "print(\"first technical description:\", ex_var.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Pandas Series of the technical descriptions\n",
    "text = df['Technical_description']\n",
    "\n",
    "# Creating the corpus\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Build the vocabulary\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# Convert text to a bag of words, returns a Compressed Sparse Row matrix\n",
    "# This is suitable for a matrix that is primarily made up of zeroes.\n",
    "x = vectorizer.transform(text)\n",
    "\n",
    "# Convert CSR_matrix to a dense matrix for easier slicing where necessary\n",
    "#x_mat = x.todense()\n",
    "\n",
    "# Convert to array\n",
    "#x = x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the vectorization, there are 32 words in the first technical description.\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the first technical description\n",
    "print(\"After the vectorization, there are\", x[0].sum(), \"words in the first technical description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        word  frequency\n",
      "order                                  \n",
      "4832                     1kv          1\n",
      "11396                  4000v          1\n",
      "21095                     av          1\n",
      "23010               benyttes          1\n",
      "23327              bestående          1\n",
      "29895                 dobbel          1\n",
      "32279                    emc          1\n",
      "32344                     en          1\n",
      "36393                flettet          1\n",
      "36714                  folie          1\n",
      "36747                    for          2\n",
      "37598              fortinnet          1\n",
      "37965  frekvensomformerkabel          1\n",
      "39633                     gi          1\n",
      "47542              jordleder          1\n",
      "48683                    kan          1\n",
      "50231           kobberskjerm          1\n",
      "50332       koblingsimpedans          1\n",
      "53403                  laget          1\n",
      "53897                 lavest          1\n",
      "58234                    med          2\n",
      "60915                  mulig          1\n",
      "63434                     og          1\n",
      "69397                     på          1\n",
      "75998              skjerming          1\n",
      "78234               spenning          1\n",
      "82028             symmetrisk          1\n",
      "84148           testspenning          1\n",
      "88797               utendørs          1\n",
      "90522                    vdf          1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'VDF/EMC frekvensomformerkabel med symmetrisk jordleder. Dobbel skjerming bestående av folie og flettet fortinnet kobberskjerm. Laget for å gi lavest mulig koblingsimpedans. Kan benyttes utendørs. For spenning 0,6/1Kv med en testspenning på 4000V'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how the vectorizer has counted the frequency of the words in the first technical description.\n",
    "# The first column constains the order of the almost 100 000 words in the corpus, the second column contains the\n",
    "# word in the technical description and the third is the frequency of that word in the first technical description.\n",
    "# Note that since two words occurs twice, only the 30 first rows are needed (instead of 32).\n",
    "# Also note how \"VDF/EMC\" is vectorized to \"vdf\" and \"emc\", and \"0,6/1Kv\" is vectorized to just \"1kv\" and\n",
    "# how all letters are in lower case.\n",
    "\n",
    "first = []\n",
    "for i in range(30):\n",
    "    for key, value in vectorizer.vocabulary_.items():\n",
    "        if value == x.indices[i]:\n",
    "            first.append({'order': value, 'frequency': x.data[i], 'word': key})\n",
    "            \n",
    "first = pd.DataFrame(first)[['order','word', 'frequency']].set_index('order')\n",
    "print(first)\n",
    "text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nword_features = vectorizer.get_feature_names()\\nprint(word_features.index('vdf'))\\nprint(x[0, word_features.index('vdf')])\\nprint(x[0, vectorizer.vocabulary_['vdf']])\\nprint(type(x))\\nprint(x.indices[0])\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "word_features = vectorizer.get_feature_names()\n",
    "print(word_features.index('vdf'))\n",
    "print(x[0, word_features.index('vdf')])\n",
    "print(x[0, vectorizer.vocabulary_['vdf']])\n",
    "print(type(x))\n",
    "print(x.indices[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# All tokens in corpus\\nprint(\"Number of products:\", x.shape[0])\\nprint(\"Number of tokens in the corpus:\", x.shape[1])\\n\\nprint(\"\")\\nprint(\"Tokens:\",vectorizer.get_feature_names())\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# All tokens in corpus\n",
    "print(\"Number of products:\", x.shape[0])\n",
    "print(\"Number of tokens in the corpus:\", x.shape[1])\n",
    "\n",
    "print(\"\")\n",
    "print(\"Tokens:\",vectorizer.get_feature_names())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202216, 94697)\n",
      "(202216,)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(df['ETIM_class'].shape)\n",
    "\n",
    "print(type(x))\n",
    "print(type(df['ETIM_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0      1      2      3      4      5      6      7      8      \\\n",
      "ProductNumber                                                                  \n",
      "1000000            0      0      0      0      0      0      0      0      0   \n",
      "1000001            0      0      0      0      0      0      0      0      0   \n",
      "1000003            0      0      0      0      0      0      0      0      0   \n",
      "1000004            0      0      0      0      0      0      0      0      0   \n",
      "1000005            0      0      0      0      0      0      0      0      0   \n",
      "\n",
      "               9      ...    94687  94688  94689  94690  94691  94692  94693  \\\n",
      "ProductNumber         ...                                                      \n",
      "1000000            0  ...        0      0      0      0      0      0      0   \n",
      "1000001            0  ...        0      0      0      0      0      0      0   \n",
      "1000003            0  ...        0      0      0      0      0      0      0   \n",
      "1000004            0  ...        0      0      0      0      0      0      0   \n",
      "1000005            0  ...        0      0      0      0      0      0      0   \n",
      "\n",
      "               94694  94695  94696  \n",
      "ProductNumber                       \n",
      "1000000            0      0      0  \n",
      "1000001            0      0      0  \n",
      "1000003            0      0      0  \n",
      "1000004            0      0      0  \n",
      "1000005            0      0      0  \n",
      "\n",
      "[5 rows x 94697 columns] ProductNumber\n",
      "1000000    10\n",
      "1000001    10\n",
      "1000003    10\n",
      "1000004    10\n",
      "1000005    10\n",
      "Name: EN_group, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x_df = pd.DataFrame(x.toarray(), index=df.index)\n",
    "\n",
    "print(x_df.head(), df['EN_group'].head())\n",
    "\n",
    "x_df.insert(0, 'ENG', df['EN_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ENG  0  1  2  3  4  5  6  7  8  ...    94687  94688  94689  \\\n",
      "ProductNumber                                 ...                          \n",
      "1000000        10  0  0  0  0  0  0  0  0  0  ...        0      0      0   \n",
      "1000001        10  0  0  0  0  0  0  0  0  0  ...        0      0      0   \n",
      "1000003        10  0  0  0  0  0  0  0  0  0  ...        0      0      0   \n",
      "1000004        10  0  0  0  0  0  0  0  0  0  ...        0      0      0   \n",
      "1000005        10  0  0  0  0  0  0  0  0  0  ...        0      0      0   \n",
      "\n",
      "               94690  94691  94692  94693  94694  94695  94696  \n",
      "ProductNumber                                                   \n",
      "1000000            0      0      0      0      0      0      0  \n",
      "1000001            0      0      0      0      0      0      0  \n",
      "1000003            0      0      0      0      0      0      0  \n",
      "1000004            0      0      0      0      0      0      0  \n",
      "1000005            0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 94698 columns]\n",
      "(202216, 94698)\n"
     ]
    }
   ],
   "source": [
    "print(x_df.head())\n",
    "print(x_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          x_df: 142.7 Gb\n",
      "                            df: 110.9 Mb\n",
      "                        ex_var:  98.3 Mb\n",
      "                          text:  86.9 Mb\n",
      "                        labels:  24.1 Mb\n",
      "                         first:   2.4 Kb\n",
      "               CountVectorizer:   1.4 Kb\n",
      "               TfidfVectorizer:   1.0 Kb\n",
      "                 MultinomialNB:   1.0 Kb\n",
      "                           _i5:   934.0b\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='b'):\n",
    "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''\n",
    "    for unit in ['',' K',' M',' G',' T',' P',' E',' Z']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = x_df.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up X and y\n",
    "X = x_df\n",
    "y = labels\n",
    "\n",
    "# Create the test and training sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "\n",
    "# Train the classifier over the training set, and test on the test set\n",
    "clf = MultinomialNB().fit(xtrain, ytrain)\n",
    "NB_train_accuracy = clf.score(xtrain, ytrain)\n",
    "NB_test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "# Accuracy scores for both the training and test sets\n",
    "print(\"Training accuracy:\", round(NB_train_accuracy, 2))\n",
    "print(\"Testing accuracy\", round(NB_test_accuracy, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "z = np.eye(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_log_proba(z)[:, 0] # takes 6,5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.argsort(probs)\n",
    "\n",
    "print(words[ind[:10]])\n",
    "print(words[ind[-10:]])\n",
    "\n",
    "print(probs[ind[:10]])\n",
    "print(probs[ind[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_view = pd.DataFrame(top_ten_view)[['order','word', 'frequency']].set_index('order')\n",
    "top_ten_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = np.eye(x.shape[1])\n",
    "probs = clf.predict_log_proba(z)[:, 0]\n",
    "ind = np.argsort(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words = words[ind[:10]]\n",
    "bad_words = words[ind[-10:]]\n",
    "\n",
    "good_prob = probs[ind[:10]]\n",
    "bad_prob = probs[ind[-10:]]\n",
    "\n",
    "print(\"Good words\\t     P(fresh | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "print(\"Bad words\\t     P(fresh | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "text\n",
    "\n",
    "text\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "response = vectorizer.fit_transform(df['Technical_description'])\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print(response)\n",
    "\n",
    "dictionary = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "\n",
    "print(max(dictionary, key=dictionary.get), dictionary[max(dictionary, key=dictionary.get)])\n",
    "\n",
    "response\n",
    "\n",
    "df = pd.DataFrame(response.toarray(), columns= vectorizer.get_feature_names())\n",
    "\n",
    "df['00000'].value_counts()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
